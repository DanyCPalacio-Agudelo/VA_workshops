{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "091db672",
   "metadata": {},
   "source": [
    "# Análisis y Tuning Avanzado de DeepForest\n",
    "Este notebook aplica ajustes de color, parameters tuning de sliding window, anchor scales y NMS, y explora múltiples valores de patch_size y score_thresh para maximizar la detección de copas (30–50 px) en las imágenes de cítricos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb2f2c2",
   "metadata": {},
   "source": [
    "## 1. Clonar repositorio y configuración inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805c6249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import git\n",
    "\n",
    "# Parámetros de repositorio y carpetas\n",
    "REPO_URL = 'https://github.com/maraosoc/citrus3-detector.git'\n",
    "REPO_DIR = 'citrus3-detector'\n",
    "DATA_DIR = os.path.join(REPO_DIR, 'data', 'samples')\n",
    "RESULT_DIR = 'resultados_citrus_tuneado'\n",
    "\n",
    "# Clonar si no existe localmente\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    print('Clonando repositorio...')\n",
    "    git.Repo.clone_from(REPO_URL, REPO_DIR)\n",
    "else:\n",
    "    print('Repositorio ya presente.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11704dfc",
   "metadata": {},
   "source": [
    "## 2. Configuración de modelo y parámetros de tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6225c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepforest import main\n",
    "\n",
    "# Cargar modelo pre-entrenado\n",
    "modelo = main.deepforest()\n",
    "modelo.use_release()\n",
    "\n",
    "# Ajustes globales para objetos pequeños (copas 30–50 px):\n",
    "modelo.config['rpn_anchor_scales'] = [16, 32, 64, 128]  # anclas más pequeñas\n",
    "modelo.config['nms_thresh'] = 0.6                     # menos supresión de cajas cercanas\n",
    "\n",
    "# Valores de patch_size a explorar y solape del 50%\n",
    "PATCH_SIZES = [256, 512, 800]\n",
    "PATCH_OVERLAP = 0.5\n",
    "\n",
    "# Umbrales de confianza a probar\n",
    "UMBRAL_ES = [0.05, 0.1, 0.3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d41f52",
   "metadata": {},
   "source": [
    "## 3. Funciones auxiliares: IoU y métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93934e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    x1 = max(box1[0], box2[0]); y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2]); y2 = min(box1[3], box2[3])\n",
    "    inter = max(0, x2-x1) * max(0, y2-y1)\n",
    "    area1 = (box1[2]-box1[0])*(box1[3]-box1[1])\n",
    "    area2 = (box2[2]-box2[0])*(box2[3]-box2[1])\n",
    "    union = area1 + area2 - inter\n",
    "    return inter/union if union>0 else 0\n",
    "\n",
    "def match_boxes(preds, truths, iou_thresh=0.4):\n",
    "    matched = set(); tp=0\n",
    "    for _, p in preds.iterrows():\n",
    "        pbox = [p.xmin,p.ymin,p.xmax,p.ymax]\n",
    "        for i, t in truths.iterrows():\n",
    "            if i in matched: continue\n",
    "            tbox = [t.xmin,t.ymin,t.xmax,t.ymax]\n",
    "            if compute_iou(pbox,tbox)>=iou_thresh:\n",
    "                tp+=1; matched.add(i); break\n",
    "    fp = len(preds)-tp; fn = len(truths)-tp\n",
    "    return tp, fp, fn\n",
    "\n",
    "def compute_metrics(tp, fp, fn):\n",
    "    precision = tp/(tp+fp) if tp+fp>0 else 0\n",
    "    recall = tp/(tp+fn) if tp+fn>0 else 0\n",
    "    f1 = 2*precision*recall/(precision+recall) if precision+recall>0 else 0\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14583594",
   "metadata": {},
   "source": [
    "## 4. Procesamiento con loops: resoluciones, patch_size y umbrales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e081b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from deepforest.visualize import plot_predictions\n",
    "\n",
    "# Definir resoluciones a evaluar\n",
    "RESOLUCIONES = {\n",
    "    'original': None,\n",
    "    'medio': (1033, 939),\n",
    "    'pequeno': (516, 469)\n",
    "}\n",
    "\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "resumen = []\n",
    "\n",
    "for img_file in os.listdir(DATA_DIR):\n",
    "    if not img_file.lower().endswith(('.tif','.png','.jpg')): continue\n",
    "    path = os.path.join(DATA_DIR, img_file)\n",
    "    name = os.path.splitext(img_file)[0]\n",
    "    # Leer BGR y convertir a RGB\n",
    "    bgr = cv2.imread(path)\n",
    "    if bgr is None: continue\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Cargar ground truth si existe\n",
    "    gt_file = os.path.join(REPO_DIR,'data','annotations',f'{name}_gt.csv')\n",
    "    truths = pd.read_csv(gt_file) if os.path.exists(gt_file) else None\n",
    "\n",
    "    for res_name, size in RESOLUCIONES.items():\n",
    "        img_res = cv2.resize(rgb, size, interpolation=cv2.INTER_AREA) if size else rgb.copy()\n",
    "        for patch in PATCH_SIZES:\n",
    "            modelo.config['patch_size'] = patch\n",
    "            modelo.config['patch_overlap'] = PATCH_OVERLAP\n",
    "            for thr in UMBRAL_ES:\n",
    "                modelo.config['score_thresh'] = thr\n",
    "                # Predicción con patch tuning explícito\n",
    "                boxes = modelo.predict_image(\n",
    "                    image=img_res,\n",
    "                    patch_size=patch,\n",
    "                    patch_overlap=PATCH_OVERLAP,\n",
    "                    return_plot=False\n",
    "                )\n",
    "                boxes = boxes[boxes.score>=thr]\n",
    "\n",
    "                # Métricas\n",
    "                if truths is not None:\n",
    "                    tp, fp, fn = match_boxes(boxes, truths)\n",
    "                    precision, recall, f1 = compute_metrics(tp, fp, fn)\n",
    "                else:\n",
    "                    tp=fp=fn=None; precision=recall=f1=None\n",
    "\n",
    "                # Guardar resultados\n",
    "                boxes.to_csv(os.path.join(\n",
    "                    RESULT_DIR, f'cajas_{res_name}_p{patch}_th{thr}_{name}.csv'\n",
    "                ), index=False)\n",
    "                # Imagen anotada\n",
    "                ann = plot_predictions(img_res, boxes)\n",
    "                ann_bgr = cv2.cvtColor(ann, cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite(os.path.join(\n",
    "                    RESULT_DIR, f'annotated_{res_name}_p{patch}_th{thr}_{name}.png'\n",
    "                ), ann_bgr)\n",
    "                # Data al resumen\n",
    "                resumen.append({\n",
    "                    'Imagen': name,\n",
    "                    'Resolución': res_name,\n",
    "                    'Patch_size': patch,\n",
    "                    'Score_thresh': thr,\n",
    "                    'Detections': len(boxes),\n",
    "                    'TP': tp, 'FP': fp, 'FN': fn,\n",
    "                    'Precision': precision, 'Recall': recall, 'F1': f1\n",
    "                })\n",
    "df = pd.DataFrame(resumen)\n",
    "df.to_csv(os.path.join(RESULT_DIR,'resumen_tuneado.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9c584c",
   "metadata": {},
   "source": [
    "## 5. Resultados\n",
    "- Todos los CSV de predicciones y las imágenes anotadas están en `resultados_citrus_tuneado`.\n",
    "- El resumen con todas las combinaciones está en `resumen_tuneado.csv`.\n",
    "\n",
    "Puedes descargar el notebook tuneado aquí:\n",
    "[Descargar Notebook Tuneado](sandbox:/mnt/data/analisis_de_arboles_tuneado.ipynb)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
