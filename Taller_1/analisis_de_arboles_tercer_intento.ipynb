{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f46cb1",
   "metadata": {},
   "source": [
    "# Análisis Ajustado de Imágenes con DeepForest\n",
    "Este notebook aplica correcciones de color (BGR→RGB), configura parámetros de sliding window (patch_size y patch_overlap) basados en el diámetro de las copas (30–50 px) y prueba tres umbrales de confianza. Además, calcula métricas de evaluación (precisión, recall, F1) y guarda resultados y las imágenes anotadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52d0427",
   "metadata": {},
   "source": [
    "## 1. Clonar repositorio y configuración inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f0f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import git\n",
    "\n",
    "# Parámetros de repositorio y carpetas\n",
    "REPO_URL = 'https://github.com/maraosoc/citrus3-detector.git'\n",
    "REPO_DIR = 'citrus3-detector'\n",
    "DATA_DIR = os.path.join(REPO_DIR, 'data', 'samples')\n",
    "RESULT_DIR = 'resultados_citrus_ajustado'\n",
    "\n",
    "# Clonar si no existe\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    print('Clonando repositorio...')\n",
    "    git.Repo.clone_from(REPO_URL, REPO_DIR)\n",
    "else:\n",
    "    print('El repositorio ya existe localmente.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943582ef",
   "metadata": {},
   "source": [
    "## 2. Configuración de modelo, sliding window y umbrales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0fdbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepforest import main\n",
    "\n",
    "# Cargar modelo pre-entrenado y parámetros de sliding window\n",
    "modelo = main.deepforest()\n",
    "modelo.use_release()\n",
    "\n",
    "# Basado en diámetro de copa (30–50 px), definimos patch_size y patch_overlap\n",
    "modelo.config['patch_size'] = 512      # tamaño de parche en px\n",
    "modelo.config['patch_overlap'] = 0.5   # solape del 50%\n",
    "\n",
    "# Lista de umbrales de confianza a probar (score_thresh)\n",
    "UMBRAL_ES = [0.05, 0.1, 0.3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c7cf96",
   "metadata": {},
   "source": [
    "## 3. Funciones auxiliares: IoU, emparejamiento y métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1945a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    \"\"\"Calcula el IoU entre dos cajas [xmin, ymin, xmax, ymax].\"\"\"\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union_area = area1 + area2 - inter_area\n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "def match_boxes(predictions, ground_truth, iou_threshold=0.4):\n",
    "    \"\"\"Empareja predicciones y ground truth según IoU y devuelve TP, FP, FN.\"\"\"\n",
    "    matched_gt = set()\n",
    "    tp = 0\n",
    "    for _, pred in predictions.iterrows():\n",
    "        pred_box = [pred.xmin, pred.ymin, pred.xmax, pred.ymax]\n",
    "        for idx, true in ground_truth.iterrows():\n",
    "            if idx in matched_gt:\n",
    "                continue\n",
    "            true_box = [true.xmin, true.ymin, true.xmax, true.ymax]\n",
    "            if compute_iou(pred_box, true_box) >= iou_threshold:\n",
    "                tp += 1\n",
    "                matched_gt.add(idx)\n",
    "                break\n",
    "    fp = len(predictions) - tp\n",
    "    fn = len(ground_truth) - tp\n",
    "    return tp, fp, fn\n",
    "\n",
    "def compute_metrics(tp, fp, fn):\n",
    "    \"\"\"Calcula precisión, recall y F1.\"\"\"\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b13feda",
   "metadata": {},
   "source": [
    "## 4. Procesamiento con corrección de color, resoluciones y umbrales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e198f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from deepforest.visualize import plot_predictions\n",
    "\n",
    "# Definición de resoluciones\n",
    "RESOLUCIONES = {\n",
    "    'original': None,             # tamaño original\n",
    "    'medio': (1033, 939),\n",
    "    'pequeno': (516, 469)\n",
    "}\n",
    "\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "resumen = []\n",
    "\n",
    "for img_file in os.listdir(DATA_DIR):\n",
    "    if not img_file.lower().endswith(('.tif', '.png', '.jpg')):\n",
    "        continue\n",
    "    img_path = os.path.join(DATA_DIR, img_file)\n",
    "    basename = os.path.splitext(img_file)[0]\n",
    "    # Leer y convertir BGR → RGB\n",
    "    img_bgr = cv2.imread(img_path)\n",
    "    if img_bgr is None:\n",
    "        continue\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Cargar ground truth si existe\n",
    "    gt_path = os.path.join(REPO_DIR, 'data', 'annotations', f'{basename}_gt.csv')\n",
    "    if os.path.exists(gt_path):\n",
    "        ground_truth = pd.read_csv(gt_path)\n",
    "    else:\n",
    "        ground_truth = None\n",
    "\n",
    "    for res_name, size in RESOLUCIONES.items():\n",
    "        # Redimensionar si aplica\n",
    "        if size:\n",
    "            img_resized = cv2.resize(img_rgb, size, interpolation=cv2.INTER_AREA)\n",
    "        else:\n",
    "            img_resized = img_rgb.copy()\n",
    "\n",
    "        for score_thresh in UMBRAL_ES:\n",
    "            modelo.config['score_thresh'] = score_thresh\n",
    "            # Predicción\n",
    "            boxes = modelo.predict_image(image=img_resized, return_plot=False)\n",
    "            boxes = boxes[boxes.score >= score_thresh]\n",
    "\n",
    "            # Evaluación\n",
    "            if ground_truth is not None:\n",
    "                tp, fp, fn = match_boxes(boxes, ground_truth)\n",
    "                precision, recall, f1 = compute_metrics(tp, fp, fn)\n",
    "            else:\n",
    "                tp = fp = fn = None\n",
    "                precision = recall = f1 = None\n",
    "\n",
    "            # Guardar CSV de predicciones\n",
    "            boxes.to_csv(\n",
    "                os.path.join(RESULT_DIR, f'cajas_{res_name}_th{score_thresh}_{basename}.csv'),\n",
    "                index=False\n",
    "            )\n",
    "            # Guardar imagen anotada (convertir RGB→BGR para cv2)\n",
    "            annotated = plot_predictions(img_resized, boxes)\n",
    "            annotated_bgr = cv2.cvtColor(annotated, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(\n",
    "                os.path.join(RESULT_DIR, f'annotated_{res_name}_th{score_thresh}_{basename}.png'),\n",
    "                annotated_bgr\n",
    "            )\n",
    "\n",
    "            # Agregar al resumen\n",
    "            resumen.append({\n",
    "                'Imagen': basename,\n",
    "                'Resolución': res_name,\n",
    "                'Score_thresh': score_thresh,\n",
    "                'Detections': len(boxes),\n",
    "                'TP': tp, 'FP': fp, 'FN': fn,\n",
    "                'Precision': precision, 'Recall': recall, 'F1': f1\n",
    "            })\n",
    "\n",
    "# Guardar resumen general\n",
    "import pandas as pd\n",
    "df_resumen = pd.DataFrame(resumen)\n",
    "df_resumen.to_csv(os.path.join(RESULT_DIR, 'resumen_general_ajustado.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbe0abd",
   "metadata": {},
   "source": [
    "## 5. Resultados\n",
    "- Los CSV de predicciones y las imágenes anotadas están en `resultados_citrus_ajustado`.\n",
    "- El resumen con métricas para cada umbral/resolución está en `resumen_general_ajustado.csv`.\n",
    "\n",
    "Puedes descargar este notebook ajustado aquí:\n",
    "[Descargar Notebook Ajustado](sandbox:/mnt/data/analisis_de_arboles_ajustado.ipynb)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
